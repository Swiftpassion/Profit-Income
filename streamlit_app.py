import streamlit as st
import pandas as pd
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from supabase import create_client, Client
import io
import datetime

# --- CONFIGURATION ---
PARENT_FOLDER_ID = '1DJp8gpZ8lntH88hXqYuZOwIyFv3NY4Ot' 

# Supabase & Google Auth
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

SCOPES = ['https://www.googleapis.com/auth/drive.readonly']
creds = service_account.Credentials.from_service_account_info(
    st.secrets["gcp_service_account"], scopes=SCOPES
)
drive_service = build('drive', 'v3', credentials=creds)

# --- HELPER FUNCTIONS ---
def list_files_in_folder(folder_id):
    query = f"'{folder_id}' in parents and trashed = false"
    results = drive_service.files().list(q=query, fields="files(id, name, mimeType)").execute()
    return results.get('files', [])

def download_file(file_id):
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while done is False:
        status, done = downloader.next_chunk()
    fh.seek(0)
    return fh

def clean_date(df, col_name):
    df[col_name] = pd.to_datetime(df[col_name], errors='coerce').dt.date
    return df

def clean_scientific_notation(val):
    val_str = str(val)
    if 'E' in val_str or 'e' in val_str:
        try:
            return str(int(float(val)))
        except:
            return val_str
    return val_str

def load_cost_data():
    try:
        response = supabase.table("product_costs").select("sku, platform, unit_cost").execute()
        df = pd.DataFrame(response.data)
        
        if not df.empty:
            df['unit_cost'] = pd.to_numeric(df['unit_cost'], errors='coerce').fillna(0)
            df['platform'] = df['platform'].str.upper().str.strip()
            df['sku'] = df['sku'].str.strip()
            df = df.drop_duplicates(subset=['sku', 'platform'], keep='last')
            return df[['sku', 'platform', 'unit_cost']]
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"Error loading Cost from DB: {e}")
        return pd.DataFrame()

def manage_costs_page():
    st.subheader("üí∞ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (Master Cost)")
    try:
        response = supabase.table("product_costs").select("*").execute()
        current_data = pd.DataFrame(response.data)
    except Exception as e:
        st.error(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        current_data = pd.DataFrame()

    if current_data.empty:
        current_data = pd.DataFrame(columns=['sku', 'platform', 'unit_cost'])

    edited_df = st.data_editor(
        current_data,
        num_rows="dynamic",
        column_config={
            "unit_cost": st.column_config.NumberColumn("‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô (‡∏ö‡∏≤‡∏ó)", min_value=0, format="%.2f"),
            "platform": st.column_config.SelectboxColumn("‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°", options=["TIKTOK", "SHOPEE", "LAZADA"], required=True),
            "sku": st.column_config.TextColumn("‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (SKU)", required=True),
        },
        use_container_width=True,
        hide_index=True,
        key="cost_editor"
    )

    if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô"):
        try:
            if not edited_df.empty:
                records = edited_df.to_dict(orient='records')
                supabase.table("product_costs").delete().neq("id", 0).execute()
                supabase.table("product_costs").insert(records).execute()
                st.success("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")
                st.rerun()
            else:
                st.warning("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")

# --- PROCESSOR: TIKTOK ---
def process_tiktok(order_files, income_files, shop_name):
    all_orders = []
    
    # 1. Process Income
    income_dfs = []
    for file_info in income_files:
        if 'xlsx' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, sheet_name='Order details', dtype=str)
                df = df.iloc[:, [47, 5, 3, 13, 24]]
                df.columns = ['order_id', 'settlement_amount', 'settlement_date', 'total_fees', 'affiliate']
                
                df['order_id'] = df['order_id'].apply(str)
                for col in ['total_fees', 'affiliate', 'settlement_amount']:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
                df['fees'] = df['total_fees'] - df['affiliate']
                income_dfs.append(df[['order_id', 'settlement_amount', 'settlement_date', 'fees', 'affiliate']])
            except Exception as e:
                st.warning(f"TikTok Income Error {file_info['name']}: {e}")

    income_master = pd.DataFrame()
    if income_dfs:
        income_master = pd.concat(income_dfs, ignore_index=True)
        income_master['order_id'] = income_master['order_id'].apply(clean_scientific_notation)
        # FIX: Use first() instead of groupby to avoid duplicates
        income_master = income_master.drop_duplicates(subset=['order_id'], keep='first')

    # 2. Process Orders
    for file_info in order_files:
        if 'xlsx' in file_info['name']:
            f_data = download_file(file_info['id'])
            df = pd.read_excel(f_data, dtype=str)
            
            if 'Shipped Time' in df.columns:
                df = df.dropna(subset=['Shipped Time'])
                
                cols_needed = {
                    'Order ID': 'order_id',
                    'Order Status': 'status',
                    'Seller SKU': 'sku',
                    'Quantity': 'quantity',
                    'SKU Subtotal After Discount': 'sales_amount',
                    'Created Time': 'created_date',
                    'Shipped Time': 'shipped_date',
                    'Tracking ID': 'tracking_id'
                }
                
                available_cols = [c for c in cols_needed.keys() if c in df.columns]
                df = df[available_cols].rename(columns=cols_needed)
                
                df['shop_name'] = shop_name
                df['platform'] = 'TIKTOK'
                df = clean_date(df, 'created_date')
                df = clean_date(df, 'shipped_date')
                df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                
                all_orders.append(df)

    if not all_orders: 
        return pd.DataFrame()

    final_df = pd.concat(all_orders, ignore_index=True)
    # FIX: Drop duplicates with specific columns
    final_df = final_df.drop_duplicates(subset=['order_id', 'sku', 'shop_name'])
    
    if not income_master.empty:
        final_df = pd.merge(final_df, income_master, on='order_id', how='left')
    
    return final_df

# --- PROCESSOR: SHOPEE ---
def process_shopee(order_files, income_files, shop_name):
    all_orders = []
    
    # 1. Process Income
    income_dfs = []
    for file_info in income_files:
        if 'xls' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, sheet_name='Income', header=5, dtype=str)
                
                rename_map = {
                    '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠': 'order_id',
                    '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à': 'settlement_date',
                    '‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥': 'original_price',
                    '‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≠‡∏°‡∏°‡∏¥‡∏ä‡∏ä‡∏±‡πà‡∏ô': 'affiliate',
                    '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß (‡∏ø)': 'settlement_amount'
                }
                
                existing_cols = [c for c in rename_map.keys() if c in df.columns]
                df = df[existing_cols].rename(columns=rename_map)
                
                for col in ['original_price', 'settlement_amount', 'affiliate']:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
                if 'original_price' in df.columns and 'settlement_amount' in df.columns:
                    df['raw_fees'] = df['original_price'] - df['settlement_amount']
                    aff_val = df['affiliate'] if 'affiliate' in df.columns else 0
                    df['fees'] = df['raw_fees'] - aff_val
                
                income_dfs.append(df)
            except Exception as e:
                st.warning(f"Shopee Income Error {file_info['name']}: {e}")
            
    income_master = pd.DataFrame()
    if income_dfs:
        income_master = pd.concat(income_dfs, ignore_index=True)
        income_master['order_id'] = income_master['order_id'].apply(clean_scientific_notation)
        income_master = income_master.drop_duplicates(subset=['order_id'], keep='first')

    # 2. Process Orders
    for file_info in order_files:
        if 'xlsx' in file_info['name']:
            f_data = download_file(file_info['id'])
            df = pd.read_excel(f_data, dtype=str)
            
            if '‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤' in df.columns:
                df = df.dropna(subset=['‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'])
                
                cols_needed = {
                    '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠': 'order_id',
                    '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠': 'status',
                    '‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤': 'shipped_date',
                    '‡πÄ‡∏•‡∏Ç‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á SKU (SKU Reference No.)': 'sku',
                    '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô': 'quantity',
                    '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏™‡∏∏‡∏ó‡∏ò‡∏¥': 'sales_amount',
                    '*‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏û‡∏±‡∏™‡∏î‡∏∏': 'tracking_id',
                    '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠': 'created_date'
                }
                
                available_cols = [c for c in cols_needed.keys() if c in df.columns]
                df = df[available_cols].rename(columns=cols_needed)

                df['shop_name'] = shop_name
                df['platform'] = 'SHOPEE'
                df = clean_date(df, 'created_date')
                df = clean_date(df, 'shipped_date')
                df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                
                all_orders.append(df)

    if not all_orders: 
        return pd.DataFrame()
    
    final_df = pd.concat(all_orders, ignore_index=True)
    # FIX: Drop duplicates with specific columns
    final_df = final_df.drop_duplicates(subset=['order_id', 'sku', 'shop_name'])

    if not income_master.empty:
        final_df = pd.merge(final_df, income_master, on='order_id', how='left')
    
    return final_df

# --- PROCESSOR: LAZADA ---
def process_lazada(order_files, income_files, shop_name):
    all_orders = []
    
    # 1. Process Income
    income_dfs = []
    for file_info in income_files:
        if 'xlsx' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, sheet_name='Income Overview', dtype=str)
                
                col_order = 'orderNumber' if 'orderNumber' in df.columns else df.columns[10]
                col_date = '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏¢‡∏≠‡∏î‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô' if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏¢‡∏≠‡∏î‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô' in df.columns else df.columns[2]
                col_amount = df.columns[3] 
                
                df = df[[col_order, col_date, col_amount]]
                df.columns = ['order_id', 'settlement_date', 'amount']
                df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0)
                
                income_dfs.append(df)
            except Exception as e:
                st.warning(f"Lazada Income Error {file_info['name']}: {e}")

    income_master = pd.DataFrame()
    if income_dfs:
        raw_income = pd.concat(income_dfs, ignore_index=True)
        raw_income['order_id'] = raw_income['order_id'].apply(clean_scientific_notation)
        
        # FIX: Use first() to avoid duplicates
        raw_income = raw_income.drop_duplicates(subset=['order_id', 'settlement_date'], keep='first')
        
        grouped = raw_income.groupby(['order_id', 'settlement_date']).agg(
            settlement_amount=('amount', lambda x: x[x > 0].sum()),
            fees=('amount', lambda x: x[x < 0].sum())
        ).reset_index()
        
        grouped['affiliate'] = 0
        income_master = grouped.drop_duplicates(subset=['order_id'], keep='first')

    # 2. Process Orders
    for file_info in order_files:
        if 'xlsx' in file_info['name']:
            f_data = download_file(file_info['id'])
            df = pd.read_excel(f_data, dtype=str)
            
            if 'trackingCode' in df.columns:
                df = df.dropna(subset=['trackingCode'])
                
                cols_needed = {
                    'orderNumber': 'order_id',
                    'status': 'status',
                    'sellerSku': 'sku',
                    'unitPrice': 'sales_amount',
                    'trackingCode': 'tracking_id',
                    'createTime': 'created_date',
                    'deliveredDate': 'shipped_date'
                }
                available_cols = [c for c in cols_needed.keys() if c in df.columns]
                df = df[available_cols].rename(columns=cols_needed)
                
                df['quantity'] = 1 
                df['shop_name'] = shop_name
                df['platform'] = 'LAZADA'
                df = clean_date(df, 'created_date')
                df = clean_date(df, 'shipped_date')
                df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                
                all_orders.append(df)
    
    if not all_orders: 
        return pd.DataFrame()
    
    final_df = pd.concat(all_orders, ignore_index=True)
    # FIX: Drop duplicates with specific columns
    final_df = final_df.drop_duplicates(subset=['order_id', 'sku', 'shop_name'])

    if not income_master.empty:
        final_df = pd.merge(final_df, income_master, on='order_id', how='left')
    
    return final_df

# --- MAIN APP ---
st.title("üõçÔ∏è Multi-Platform E-Commerce Dashboard")
tab1, tab2 = st.tabs(["üöÄ Sync & Dashboard", "üí∞ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô (Master Cost)"])

with tab1:
    if st.button("üöÄ Sync Data from Google Drive"):
        st.write("üîÑ **Start Debugging Process...**")
        
        with st.spinner("Connecting to Google Drive..."):
            root_files = list_files_in_folder(PARENT_FOLDER_ID)
            
            if len(root_files) == 0:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πá‡∏Ñ PARENT_FOLDER_ID ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á")
                st.stop()

            folder_map = {f['name']: f['id'] for f in root_files if f['mimeType'] == 'application/vnd.google-apps.folder'}
            
            shops = {
                'TIKTOK': ['TIKTOK 1', 'TIKTOK 2', 'TIKTOK 3'],
                'SHOPEE': ['SHOPEE 1', 'SHOPEE 2', 'SHOPEE 3'],
                'LAZADA': ['LAZADA 1', 'LAZADA 2', 'LAZADA 3']
            }
            income_folders = {'TIKTOK': 'INCOME TIKTOK', 'SHOPEE': 'INCOME SHOPEE', 'LAZADA': 'INCOME LAZADA'}
            
            all_data = []
            
            # --- 1. Loop ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
            for platform, shop_list in shops.items():
                inc_folder_name = income_folders.get(platform)
                inc_files = list_files_in_folder(folder_map.get(inc_folder_name, ''))
                
                for shop_name in shop_list:
                    if shop_name in folder_map:
                        order_files = list_files_in_folder(folder_map[shop_name])
                        
                        df_res = pd.DataFrame()
                        try:
                            if platform == 'TIKTOK': df_res = process_tiktok(order_files, inc_files, shop_name)
                            elif platform == 'SHOPEE': df_res = process_shopee(order_files, inc_files, shop_name)
                            elif platform == 'LAZADA': df_res = process_lazada(order_files, inc_files, shop_name)
                        except Exception as e:
                            st.error(f"  ‚ùå Error processing {shop_name}: {e}")

                        if not df_res.empty:
                            all_data.append(df_res)
                            st.success(f"  ‚úÖ {shop_name}: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ {len(df_res)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
            # --- 2. ‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ---
            if all_data:
                master_df = pd.concat(all_data, ignore_index=True)
                # FIX: Final deduplication across all platforms
                master_df = master_df.drop_duplicates(subset=['order_id', 'sku', 'shop_name', 'platform'])
                
                st.info(f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö: {len(master_df)} ‡πÅ‡∏ñ‡∏ß -> ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
                
                # Debug: Show duplicates if any
                duplicate_count = master_df.duplicated(subset=['order_id', 'sku', 'shop_name', 'platform']).sum()
                if duplicate_count > 0:
                    st.warning(f"‚ö†Ô∏è ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô {duplicate_count} ‡πÅ‡∏ñ‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡∏ã‡πâ‡∏≥‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å")

                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                cols_num = ['quantity', 'sales_amount', 'settlement_amount', 'fees', 'affiliate']
                for col in cols_num:
                    if col in master_df.columns:
                        master_df[col] = pd.to_numeric(master_df[col], errors='coerce').fillna(0)
                    else:
                        master_df[col] = 0.0

                # ‡∏´‡∏≤‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå
                order_totals = master_df.groupby('order_id')['sales_amount'].transform('sum')
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô (Ratio) ‡πÅ‡∏•‡∏∞‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô
                ratio = master_df['sales_amount'] / order_totals.replace(0, 1)
                
                # ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô
                for col in ['settlement_amount', 'fees', 'affiliate']:
                    if col in master_df.columns:
                        master_df[col] = master_df[col] * ratio

                # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö Lazada Affiliate ‡πÄ‡∏õ‡πá‡∏ô 0
                if 'platform' in master_df.columns:
                    master_df.loc[master_df['platform'] == 'LAZADA', 'affiliate'] = 0

                # --- 3. ‡∏î‡∏∂‡∏á‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô & ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≥‡πÑ‡∏£ ---
                cost_df = load_cost_data()
                if not cost_df.empty:
                    # FIX: Merge properly
                    master_df = pd.merge(
                        master_df, 
                        cost_df, 
                        on=['sku', 'platform'], 
                        how='left'
                    )
                    # Handle duplicate column names
                    if 'unit_cost_x' in master_df.columns and 'unit_cost_y' in master_df.columns:
                        master_df['unit_cost'] = master_df['unit_cost_y'].fillna(0)
                        master_df = master_df.drop(columns=['unit_cost_x', 'unit_cost_y'], errors='ignore')
                else:
                    master_df['unit_cost'] = 0

                master_df['unit_cost'] = master_df['unit_cost'].fillna(0)
                master_df['total_cost'] = master_df['quantity'] * master_df['unit_cost']
                master_df['net_profit'] = master_df['settlement_amount'] - master_df['total_cost']

                # Final cleanup
                master_df = master_df.replace([float('inf'), float('-inf')], 0)
                
                # Format ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                for col in ['created_date', 'shipped_date', 'settlement_date']:
                    if col in master_df.columns:
                        master_df[col] = master_df[col].astype(str).replace({'nan': None, 'None': None})

                # Final deduplication check before upload
                final_duplicates = master_df.duplicated(subset=['order_id', 'sku', 'shop_name', 'platform']).sum()
                if final_duplicates > 0:
                    st.warning(f"‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ {final_duplicates} ‡πÅ‡∏ñ‡∏ß ‡∏à‡∏∞‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
                    master_df = master_df.drop_duplicates(subset=['order_id', 'sku', 'shop_name', 'platform'])
                
                st.info(f"üì§ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î {len(master_df)} ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô")

                # --- 4. UPLOAD ---
                st.warning("‚ö†Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà...")
                
                try:
                    supabase.table("orders").delete().neq("id", 0).execute()
                except Exception as e:
                    st.error(f"‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

                st.info("‚òÅÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà...")
                records = master_df.to_dict(orient='records')
                
                chunk_size = 500
                total_uploaded = 0
                error_count = 0
                progress_bar = st.progress(0)
                
                for i in range(0, len(records), chunk_size):
                    chunk = records[i:i + chunk_size]
                    try:
                        supabase.table("orders").insert(chunk).execute()
                        total_uploaded += len(chunk)
                    except Exception as e:
                        error_count += 1
                        st.error(f"‚ùå Upload Error (Chunk {i}): {e}")
                    
                    progress_bar.progress(min((i + chunk_size) / len(records), 1.0))
                
                if error_count == 0:
                    st.success(f"‚úÖ Sync ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ({total_uploaded} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")
                    st.rerun()
                else:
                    st.error(f"‚ö†Ô∏è ‡∏°‡∏µ {error_count} chunk ‡∏ó‡∏µ‡πà‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
            else:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")

    # ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ
    st.divider()
    st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (Summary)")
    
    try:
        response = supabase.table("orders").select("*").execute()
        db_df = pd.DataFrame(response.data)
        
        if not db_df.empty:
            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{len(db_df)}")
            
            # Display table
            col_order = [
                'order_id', 'status', 'sku', 'quantity', 'sales_amount',
                'settlement_amount', 'net_profit', 'total_cost', 'fees',
                'affiliate', 'settlement_date', 'created_date', 'shipped_date',
                'tracking_id', 'shop_name', 'platform'
            ]
            
            rename_map = {
                'order_id': '‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠',
                'status': '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞',
                'sku': '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤',
                'quantity': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô',
                'sales_amount': '‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢',
                'settlement_amount': '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö',
                'net_profit': '‡∏Å‡∏≥‡πÑ‡∏£',
                'total_cost': '‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô',
                'fees': '‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°',
                'affiliate': '‡πÅ‡∏≠‡∏ü‡∏ü‡∏¥‡∏•‡∏¥‡πÄ‡∏≠‡∏ï',
                'settlement_date': '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÄ‡∏á‡∏¥‡∏ô',
                'created_date': '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠',
                'shipped_date': '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
                'tracking_id': '‡πÄ‡∏•‡∏Ç‡∏û‡∏±‡∏™‡∏î‡∏∏',
                'shop_name': '‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô',
                'platform': '‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°'
            }

            final_cols = [c for c in col_order if c in db_df.columns]
            display_df = db_df[final_cols].rename(columns=rename_map)
            
            st.dataframe(
                display_df, 
                use_container_width=True,
                hide_index=True
            )
        else:
            st.info("‚ÑπÔ∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Sync ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")

with tab2:
    manage_costs_page()