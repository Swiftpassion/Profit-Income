import streamlit as st
import pandas as pd
import numpy as np
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from supabase import create_client, Client
import io
import datetime
import calendar
from datetime import date
import math

# --- 1. CONFIGURATION & CSS ---
st.set_page_config(page_title="Dashboard ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£", layout="wide", page_icon="üõçÔ∏è")

# Custom CSS
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Kanit:wght@300;400;600&display=swap');
    html, body, [class*="css"] { font-family: 'Kanit', sans-serif; }
    .stMetric { background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #dee2e6; }
    div[data-testid="stDataFrameResizable"] { border: 1px solid #e0e0e0; border-radius: 8px; }
    </style>
""", unsafe_allow_html=True)

# Supabase & Google Auth
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    SCOPES = ['https://www.googleapis.com/auth/drive.readonly']
    creds = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"], scopes=SCOPES
    )
    drive_service = build('drive', 'v3', credentials=creds)
    PARENT_FOLDER_ID = '1DJp8gpZ8lntH88hXqYuZOwIyFv3NY4Ot' # ID ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô Drive
except Exception as e:
    st.error(f"‚ùå Config Error: {e}")
    st.stop()

# --- 2. HELPER FUNCTIONS (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô) ---

def list_files_in_folder(folder_id):
    try:
        query = f"'{folder_id}' in parents and trashed = false"
        results = drive_service.files().list(q=query, fields="files(id, name, mimeType)").execute()
        return results.get('files', [])
    except: return []

def download_file(file_id):
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while done is False:
        status, done = downloader.next_chunk()
    fh.seek(0)
    return fh

def clean_date(df, col_name):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD ‡∏ï‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏¥‡πâ‡∏á"""
    if col_name in df.columns:
        df[col_name] = pd.to_datetime(df[col_name], errors='coerce', dayfirst=True).dt.date
    return df

def clean_text(df, col_name):
    if col_name in df.columns:
        df[col_name] = df[col_name].astype(str).str.strip().str.upper()
    return df

def clean_scientific_notation(val):
    val_str = str(val).strip()
    if 'E' in val_str or 'e' in val_str:
        try:
            return str(int(float(val)))
        except:
            return val_str
    return val_str

def get_standard_status(row):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    try:
        amt = float(row.get('settlement_amount', 0))
    except:
        amt = 0
    if amt > 0: return "‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"
    
    raw_status = str(row.get('status', '')).lower()
    if any(x in raw_status for x in ['‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å', 'cancel']): return "‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å"
    if any(x in raw_status for x in ['package returned', 'return', '‡∏ï‡∏µ‡∏Å‡∏•‡∏±‡∏ö']): return "‡∏ï‡∏µ‡∏Å‡∏•‡∏±‡∏ö"
    return "‡∏£‡∏≠‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£"

def load_cost_data():
    """‡πÇ‡∏´‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"""
    try:
        response = supabase.table("product_costs").select("sku, platform, unit_cost").execute()
        df = pd.DataFrame(response.data)
        if not df.empty:
            df['unit_cost'] = pd.to_numeric(df['unit_cost'], errors='coerce').fillna(0)
            df['platform'] = df['platform'].str.upper().str.strip()
            df = clean_text(df, 'sku')
            return df[['sku', 'platform', 'unit_cost']]
        return pd.DataFrame()
    except: return pd.DataFrame()

# --- 3. PROCESSORS (‡∏ï‡∏±‡∏ß‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° - ‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß) ---

def process_tiktok(order_files, income_files, shop_name):
    all_orders = []
    # Income
    income_dfs = []
    for file_info in income_files:
        if 'xlsx' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, sheet_name='Order details', dtype=str)
                df = df.iloc[:, [47, 5, 3, 13, 24]]
                df.columns = ['order_id', 'settlement_amount', 'settlement_date', 'total_fees', 'affiliate']
                df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                for col in ['total_fees', 'affiliate', 'settlement_amount']:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                df['fees'] = df['total_fees'] - df['affiliate']
                income_dfs.append(df[['order_id', 'settlement_amount', 'settlement_date', 'fees', 'affiliate']])
            except: pass
    
    income_master = pd.DataFrame()
    if income_dfs:
        income_master = pd.concat(income_dfs, ignore_index=True)
        income_master = income_master.groupby('order_id').first().reset_index()

    # Orders
    for file_info in order_files:
        if 'xlsx' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, dtype=str)
                if 'Shipped Time' in df.columns:
                    df = df.dropna(subset=['Shipped Time'])
                    df = df[df['Shipped Time'].astype(str).str.strip() != '']
                    cols = {'Order ID':'order_id', 'Order Status':'status', 'Seller SKU':'sku', 'Quantity':'quantity', 
                            'SKU Subtotal After Discount':'sales_amount', 'Created Time':'created_date', 
                            'Shipped Time':'shipped_date', 'Tracking ID':'tracking_id'}
                    df = df[[c for c in cols if c in df.columns]].rename(columns=cols)
                    df['shop_name'] = shop_name; df['platform'] = 'TIKTOK'
                    df = clean_date(df, 'created_date'); df = clean_date(df, 'shipped_date')
                    df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                    df = clean_text(df, 'sku')
                    all_orders.append(df)
            except: pass

    if not all_orders: return pd.DataFrame()
    final_df = pd.concat(all_orders, ignore_index=True)
    if not final_df.empty: final_df = final_df.drop_duplicates(subset=['order_id', 'sku'], keep='first')
    if not income_master.empty: final_df = pd.merge(final_df, income_master, on='order_id', how='left')
    return final_df

def process_shopee(order_files, income_files, shop_name):
    all_orders = []
    # Income
    income_dfs = []
    for file_info in income_files:
        if any(x in file_info['name'].lower() for x in ['xls', 'csv']):
            try:
                f_data = download_file(file_info['id'])
                if 'csv' in file_info['name'].lower():
                    try: df = pd.read_csv(f_data, dtype=str, encoding='utf-8')
                    except: f_data.seek(0); df = pd.read_csv(f_data, dtype=str, encoding='cp874')
                else: df = pd.read_excel(f_data, sheet_name='Income', header=5, dtype=str)
                
                df.columns = df.columns.str.strip()
                rename = {'‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠':'order_id', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à':'settlement_date', 
                          '‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥':'original_price', '‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≠‡∏°‡∏°‡∏¥‡∏ä‡∏ä‡∏±‡πà‡∏ô':'affiliate', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß (‡∏ø)':'settlement_amount'}
                df = df[[c for c in rename if c in df.columns]].rename(columns=rename)
                for c in ['original_price', 'settlement_amount', 'affiliate']: 
                    if c in df.columns: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
                if 'original_price' in df.columns: 
                    df['fees'] = df['original_price'] - df['settlement_amount'] - df.get('affiliate',0)
                income_dfs.append(df)
            except: pass
            
    income_master = pd.DataFrame()
    if income_dfs:
        income_master = pd.concat(income_dfs, ignore_index=True)
        income_master['order_id'] = income_master['order_id'].apply(clean_scientific_notation)
        cols = [c for c in ['order_id', 'settlement_amount', 'settlement_date', 'fees', 'affiliate'] if c in income_master.columns]
        income_master = income_master[cols].drop_duplicates(subset=['order_id'])

    # Orders (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏≤ Header ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠)
    for file_info in order_files:
        if any(x in file_info['name'].lower() for x in ['xls', 'csv']):
            try:
                f_data = download_file(file_info['id'])
                if 'csv' in file_info['name'].lower():
                    for enc in ['utf-8', 'cp874', 'utf-8-sig']:
                        try:
                            f_data.seek(0); temp = pd.read_csv(f_data, encoding=enc, dtype=str)
                            header_row = -1
                            if '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠' in temp.columns: header_row = 0
                            else:
                                for i, r in temp.head(20).iterrows():
                                    if any('‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠' in str(v) for v in r.values): header_row = i+1; break
                            if header_row != -1:
                                f_data.seek(0); df = pd.read_csv(f_data, encoding=enc, dtype=str, skiprows=header_row); break
                        except: continue
                else: df = pd.read_excel(f_data, dtype=str)

                if df.empty: continue
                df.columns = df.columns.str.strip()
                
                if '‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤' in df.columns:
                    df = df.dropna(subset=['‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'])
                    df = df[df['‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip() != '']
                    cols = {'‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠':'order_id', '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠':'status', '‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'shipped_date',
                            '‡πÄ‡∏•‡∏Ç‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á SKU (SKU Reference No.)':'sku', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô':'quantity', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏™‡∏∏‡∏ó‡∏ò‡∏¥':'sales_amount',
                            '*‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏û‡∏±‡∏™‡∏î‡∏∏':'tracking_id', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠':'created_date'}
                    df = df[[c for c in cols if c in df.columns]].rename(columns=cols)
                    df['shop_name'] = shop_name; df['platform'] = 'SHOPEE'
                    df = clean_date(df, 'created_date'); df = clean_date(df, 'shipped_date')
                    df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                    df = clean_text(df, 'sku')
                    all_orders.append(df)
            except: pass

    if not all_orders: return pd.DataFrame()
    final_df = pd.concat(all_orders, ignore_index=True)
    if not final_df.empty: final_df = final_df.drop_duplicates(subset=['order_id', 'sku'], keep='first')
    if not income_master.empty: final_df = pd.merge(final_df, income_master, on='order_id', how='left')
    return final_df

def process_lazada(order_files, income_files, shop_name):
    all_orders = []
    # Income
    income_dfs = []
    for file_info in income_files:
        if 'xlsx' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, sheet_name='Income Overview', dtype=str)
                col_order = df.columns[0] if 'orderNumber' in df.columns else df.columns[10]
                col_amt = df.columns[3]
                df = df[[col_order, df.columns[2], col_amt]]
                df.columns = ['order_id', 'settlement_date', 'amount']
                df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0)
                income_dfs.append(df)
            except: pass

    income_master = pd.DataFrame()
    if income_dfs:
        raw = pd.concat(income_dfs, ignore_index=True)
        raw['order_id'] = raw['order_id'].apply(clean_scientific_notation)
        income_master = raw.groupby(['order_id']).agg(
            settlement_amount=('amount', lambda x: x[x>0].sum()),
            fees=('amount', lambda x: x[x<0].sum())
        ).reset_index()
        income_master['affiliate'] = 0

    # Orders
    for file_info in order_files:
        if 'xlsx' in file_info['name']:
            try:
                f_data = download_file(file_info['id'])
                df = pd.read_excel(f_data, dtype=str)
                if 'trackingCode' in df.columns:
                    df = df.dropna(subset=['trackingCode'])
                    df = df[df['trackingCode'].astype(str).str.strip() != '']
                    cols = {'orderNumber':'order_id', 'status':'status', 'sellerSku':'sku', 'unitPrice':'sales_amount',
                            'trackingCode':'tracking_id', 'createTime':'created_date', 'deliveredDate':'shipped_date'}
                    df = df[[c for c in cols if c in df.columns]].rename(columns=cols)
                    df['quantity'] = 1; df['shop_name'] = shop_name; df['platform'] = 'LAZADA'
                    df = clean_date(df, 'created_date'); df = clean_date(df, 'shipped_date')
                    df['order_id'] = df['order_id'].apply(clean_scientific_notation)
                    df = clean_text(df, 'sku')
                    all_orders.append(df)
            except: pass

    if not all_orders: return pd.DataFrame()
    final_df = pd.concat(all_orders, ignore_index=True)
    if not final_df.empty: final_df = final_df.drop_duplicates(subset=['order_id', 'sku'], keep='first')
    if not income_master.empty: final_df = pd.merge(final_df, income_master, on='order_id', how='left')
    return final_df

# --- 4. MAIN APPLICATION ---

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Tabs ‡∏´‡∏•‡∏±‡∏Å
tab1, tab2, tab3 = st.tabs(["üöÄ Sync ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏´‡∏•‡∏±‡∏á‡∏ö‡πâ‡∏≤‡∏ô)", "üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ & ‡∏Å‡∏≥‡πÑ‡∏£ (‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà)", "üí∞ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô"])

# ==========================================
# TAB 1: SYNC DATA (‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏á‡∏ö‡πâ‡∏≤‡∏ô)
# ==========================================
with tab1:
    st.subheader("üîÑ ‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Drive")
    col_sync, col_debug = st.columns([2, 1])
    with col_sync:
        start_sync = st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Sync Data (‡∏•‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏•‡∏á‡πÉ‡∏´‡∏°‡πà)", type="primary")
    with col_debug:
        debug_mode = st.checkbox("‡πÇ‡∏´‡∏°‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Debug)", value=False)

    if start_sync:
        st.info("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Drive...")
        root_files = list_files_in_folder(PARENT_FOLDER_ID)
        
        if not root_files:
            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å")
            st.stop()

        folder_map = {f['name']: f['id'] for f in root_files if f['mimeType'] == 'application/vnd.google-apps.folder'}
        shops = {'TIKTOK': ['TIKTOK 1', 'TIKTOK 2', 'TIKTOK 3'], 'SHOPEE': ['SHOPEE 1', 'SHOPEE 2', 'SHOPEE 3'], 'LAZADA': ['LAZADA 1', 'LAZADA 2', 'LAZADA 3']}
        inc_folders = {'TIKTOK': 'INCOME TIKTOK', 'SHOPEE': 'INCOME SHOPEE', 'LAZADA': 'INCOME LAZADA'}
        
        all_data = []
        progress_text = st.empty()

        for platform, shop_list in shops.items():
            inc_id = folder_map.get(inc_folders.get(platform), '')
            inc_files = list_files_in_folder(inc_id)
            
            for shop_name in shop_list:
                if shop_name in folder_map:
                    progress_text.text(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {shop_name}...")
                    order_files = list_files_in_folder(folder_map[shop_name])
                    
                    df_res = pd.DataFrame()
                    if platform == 'TIKTOK': df_res = process_tiktok(order_files, inc_files, shop_name)
                    elif platform == 'SHOPEE': df_res = process_shopee(order_files, inc_files, shop_name)
                    elif platform == 'LAZADA': df_res = process_lazada(order_files, inc_files, shop_name)

                    if not df_res.empty:
                        all_data.append(df_res)
                        st.success(f"‚úÖ {shop_name}: {len(df_res)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                        if debug_mode: st.dataframe(df_res.head(2))

        if all_data:
            master_df = pd.concat(all_data, ignore_index=True)
            # Deduplicate
            master_df = master_df.drop_duplicates(subset=['order_id', 'sku'], keep='first')
            
            st.info("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Pro-rate ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≥‡πÑ‡∏£...")
            
            # Numeric conversion
            for c in ['quantity', 'sales_amount', 'settlement_amount', 'fees', 'affiliate', 'unit_cost']:
                if c in master_df.columns: master_df[c] = pd.to_numeric(master_df[c], errors='coerce').fillna(0)
                else: master_df[c] = 0.0

            # Pro-rate Logic
            order_totals = master_df.groupby('order_id')['sales_amount'].transform('sum')
            ratio = master_df['sales_amount'] / order_totals.replace(0, 1)
            master_df['settlement_amount'] *= ratio
            master_df['fees'] *= ratio
            master_df['affiliate'] *= ratio
            
            if 'platform' in master_df.columns:
                master_df.loc[master_df['platform'] == 'LAZADA', 'affiliate'] = 0

            # Cost & Profit
            cost_df = load_cost_data()
            if not cost_df.empty:
                master_df = pd.merge(master_df, cost_df, on=['sku', 'platform'], how='left')
                if 'unit_cost_y' in master_df.columns:
                    master_df['unit_cost'] = master_df['unit_cost_y'].fillna(0)
                    master_df = master_df.drop(columns=['unit_cost_x', 'unit_cost_y'], errors='ignore')
            
            master_df['unit_cost'] = master_df['unit_cost'].fillna(0)
            master_df['total_cost'] = master_df['quantity'] * master_df['unit_cost']
            master_df['net_profit'] = master_df['settlement_amount'] - master_df['total_cost']

            # Standard Status
            master_df['status'] = master_df.apply(get_standard_status, axis=1)

            # Date Format & Clean
            for c in ['created_date', 'shipped_date', 'settlement_date']:
                if c in master_df.columns: master_df[c] = master_df[c].astype(str).replace({'nan': None, 'None': None})
            
            valid_cols = ['order_id', 'status', 'sku', 'quantity', 'sales_amount', 'settlement_amount', 'fees', 'affiliate', 
                          'net_profit', 'total_cost', 'unit_cost', 'settlement_date', 'created_date', 'shipped_date', 
                          'tracking_id', 'shop_name', 'platform']
            master_df = master_df[[c for c in valid_cols if c in master_df.columns]]

            # Upload
            st.warning("‚ö†Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏•‡∏á‡πÉ‡∏´‡∏°‡πà...")
            try: supabase.table("orders").delete().neq("id", 0).execute()
            except: pass
            
            records = master_df.to_dict(orient='records')
            
            # Sanitize NaN/Inf
            clean_records = []
            for r in records:
                new_r = {}
                for k, v in r.items():
                    if isinstance(v, float) and (math.isnan(v) or math.isinf(v)): new_r[k] = 0.0
                    else: new_r[k] = v
                clean_records.append(new_r)

            chunk_size = 500; total = 0
            bar = st.progress(0)
            for i in range(0, len(clean_records), chunk_size):
                chunk = clean_records[i:i+chunk_size]
                try:
                    supabase.table("orders").insert(chunk).execute()
                    total += len(chunk)
                except Exception as e: st.error(f"Error chunk {i}: {e}")
                bar.progress(min((i+chunk_size)/len(clean_records), 1.0))
            
            st.success(f"‚úÖ Sync ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ({total} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")
            st.rerun()

    # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (Backup)
    st.divider()
    if st.checkbox("‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° (Backup)"):
        try:
            res = supabase.table("orders").select("*").execute()
            if res.data:
                st.dataframe(pd.DataFrame(res.data).head(50))
        except: pass

# ==========================================
# TAB 2: DASHBOARD (‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏™‡∏±‡πà‡∏á)
# ==========================================
with tab2:
    st.header("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° (Detailed Dashboard)")
    
    # 1. Date Filters
    thai_months = ["‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°", "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå", "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°", "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô", "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°", "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô",
                   "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°", "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°", "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô", "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°", "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô", "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°"]
    today = datetime.datetime.now().date()
    all_years = sorted([2024, 2025, 2026], reverse=True)

    def update_dates():
        y = st.session_state.sel_year
        m_str = st.session_state.sel_month
        try:
            m_idx = thai_months.index(m_str) + 1
            _, days = calendar.monthrange(y, m_idx)
            st.session_state.d_start = date(y, m_idx, 1)
            st.session_state.d_end = date(y, m_idx, days)
        except: pass

    if "d_start" not in st.session_state:
        st.session_state.d_start = today.replace(day=1)
        st.session_state.d_end = today

    with st.container():
        st.subheader("üîç ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
        c1, c2, c3, c4 = st.columns(4)
        with c1: st.selectbox("‡∏õ‡∏µ", options=all_years, index=0, key="sel_year", on_change=update_dates)
        with c2: st.selectbox("‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", options=thai_months, index=today.month-1, key="sel_month", on_change=update_dates)
        with c3: d_start = st.date_input("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°", key="d_start")
        with c4: d_end = st.date_input("‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", key="d_end")

    # 2. Platform Filters
    st.write("üõçÔ∏è **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°**")
    cp1, cp2, cp3, cp4, cp5 = st.columns([1, 1, 1, 1, 6])
    with cp1: all_plat = st.checkbox("‚úÖ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", value=True)
    with cp2: tiktok_check = st.checkbox("‚úÖ Tiktok", value=all_plat, disabled=all_plat)
    with cp3: shopee_check = st.checkbox("‚úÖ Shopee", value=all_plat, disabled=all_plat)
    with cp4: lazada_check = st.checkbox("‚úÖ Lazada", value=all_plat, disabled=all_plat)

    sel_plats = []
    if all_plat: sel_plats = ['TIKTOK', 'SHOPEE', 'LAZADA']
    else:
        if tiktok_check: sel_plats.append('TIKTOK')
        if shopee_check: sel_plats.append('SHOPEE')
        if lazada_check: sel_plats.append('LAZADA')

    # 3. Data Fetching & Processing
    try:
        res = supabase.table("orders").select("*").execute()
        raw_df = pd.DataFrame(res.data)
        
        if not raw_df.empty:
            # Filter Data
            raw_df['created_date'] = pd.to_datetime(raw_df['created_date']).dt.date
            mask = (raw_df['created_date'] >= d_start) & (raw_df['created_date'] <= d_end)
            if 'platform' in raw_df.columns:
                mask &= raw_df['platform'].str.upper().isin(sel_plats)
            
            df = raw_df.loc[mask].copy()

            # Clean Numbers
            for c in ['sales_amount', 'settlement_amount', 'fees', 'affiliate', 'total_cost']:
                if c in df.columns: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)

            # Group by Date
            date_range = pd.date_range(start=d_start, end=d_end)
            dates_df = pd.DataFrame({'created_date': date_range.date})
            
            daily = df.groupby('created_date').agg(
                success_count=('status', lambda x: (x == '‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à').sum()),
                pending_count=('status', lambda x: (x == '‡∏£‡∏≠‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£').sum()),
                return_count=('status', lambda x: (x == '‡∏ï‡∏µ‡∏Å‡∏•‡∏±‡∏ö').sum()),
                cancel_count=('status', lambda x: (x == '‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å').sum()),
                sales_sum=('sales_amount', 'sum'),
                cost_sum=('total_cost', 'sum'),
                fees_sum=('fees', 'sum'),
                affiliate_sum=('affiliate', 'sum')
            ).reset_index()
            
            final_df = pd.merge(dates_df, daily, on='created_date', how='left').fillna(0)

            # 4. Ads Input (Session State)
            if "ads_data" not in st.session_state: st.session_state.ads_data = {}
            
            editor_data = []
            for _, row in final_df.iterrows():
                d_str = str(row['created_date'])
                saved = st.session_state.ads_data.get(d_str, {'ads': 0.0, 'roas': 0.0})
                r_dict = row.to_dict()
                r_dict['manual_ads'] = saved['ads']
                r_dict['manual_roas'] = saved['roas']
                editor_data.append(r_dict)
            
            editor_df = pd.DataFrame(editor_data)

            # 5. Data Editor (Input)
            st.markdown("### üìù ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ ADS (‡∏ä‡πà‡∏≠‡∏á‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á)")
            edited = st.data_editor(
                editor_df,
                column_config={
                    "created_date": st.column_config.DateColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", format="DD MMM YYYY", disabled=True),
                    "sales_sum": st.column_config.NumberColumn("‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢", format="‡∏ø%.2f", disabled=True),
                    "manual_ads": st.column_config.NumberColumn("üì¢ ‡∏Ñ‡πà‡∏≤ ADS", format="‡∏ø%.2f", required=True),
                    "manual_roas": st.column_config.NumberColumn("üìà ROAS ADS", format="‡∏ø%.2f", required=True),
                },
                use_container_width=True, hide_index=True, key="main_editor",
                column_order=['created_date', 'sales_sum', 'manual_ads', 'manual_roas']
            )

            # Save Input
            for _, row in edited.iterrows():
                st.session_state.ads_data[str(row['created_date'])] = {'ads': row['manual_ads'], 'roas': row['manual_roas']}

            # 6. Final Calculation
            calc = edited.copy()
            def safe_div(a, b): return (a/b*100) if b > 0 else 0

            # Profit Calc
            calc['‡∏Å‡∏≥‡πÑ‡∏£'] = calc['sales_sum'] - calc['cost_sum'] - calc['fees_sum'] - calc['affiliate_sum']
            
            # Ads Calc
            calc['ADS VAT 7%'] = calc['manual_ads'] * 0.07
            calc['‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°'] = calc['manual_ads'] + calc['manual_roas'] + calc['ADS VAT 7%']
            calc['ROAS'] = calc.apply(lambda x: (x['sales_sum']/x['‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°']) if x['‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°'] > 0 else 0, axis=1)

            # Net Profit
            ops_count = calc['success_count'] + calc['pending_count'] + calc['return_count'] + calc['cancel_count']
            calc['‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£'] = ops_count * 10
            calc['‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥'] = calc['‡∏Å‡∏≥‡πÑ‡∏£'] - calc['‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°'] - calc['‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£']

            # Percentages
            for c in ['cost_sum', 'fees_sum', 'affiliate_sum', '‡∏Å‡∏≥‡πÑ‡∏£', '‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°', '‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥']:
                calc[f'%{c}'] = calc.apply(lambda x: safe_div(x[c], x['sales_sum']), axis=1)

            # 7. Final Table Display
            st.markdown("### üèÅ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)")
            view = calc.rename(columns={
                'created_date':'‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 'success_count':'‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à', 'pending_count':'‡∏£‡∏≠‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£',
                'return_count':'‡∏ï‡∏µ‡∏Å‡∏•‡∏±‡∏ö', 'cancel_count':'‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å', 'sales_sum':'‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°',
                'cost_sum':'‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°', '%cost_sum':'%‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°',
                'fees_sum':'‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°', '%fees_sum':'%‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°',
                'affiliate_sum':'‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏ü‡∏ü‡∏¥‡∏•‡∏¥‡πÄ‡∏≠‡∏ï', '%affiliate_sum':'%‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏ü‡∏ü‡∏¥‡∏•‡∏¥‡πÄ‡∏≠‡∏ï',
                '%‡∏Å‡∏≥‡πÑ‡∏£':'%‡∏Å‡∏≥‡πÑ‡∏£', 'manual_ads':'‡∏Ñ‡πà‡∏≤ADS', 'manual_roas':'ROAS ADS',
                '%‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°':'%‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î', '%‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£':'%‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '%‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥':'%‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥'
            })
            
            final_cols = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à', '‡∏£‡∏≠‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '‡∏ï‡∏µ‡∏Å‡∏•‡∏±‡∏ö', '‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å', '‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°', 'ROAS',
                          '‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°', '%‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°', '‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°', '%‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°', '‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏ü‡∏ü‡∏¥‡∏•‡∏¥‡πÄ‡∏≠‡∏ï', '%‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏ü‡∏ü‡∏¥‡∏•‡∏¥‡πÄ‡∏≠‡∏ï',
                          '‡∏Å‡∏≥‡πÑ‡∏£', '%‡∏Å‡∏≥‡πÑ‡∏£', '‡∏Ñ‡πà‡∏≤ADS', 'ROAS ADS', 'ADS VAT 7%', '‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î‡∏£‡∏ß‡∏°', '%‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏î',
                          '‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '%‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥', '%‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥']
            
            st.dataframe(
                view[final_cols],
                column_config={
                    "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": st.column_config.DateColumn(format="DD/MM/YYYY"),
                    "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°": st.column_config.NumberColumn(format="%.2f"),
                    "‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥": st.column_config.ProgressColumn(format="‡∏ø%.2f", min_value=0, max_value=float(view['‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥'].max()) if not view.empty else 100),
                    **{c: st.column_config.NumberColumn(format="%.2f") for c in final_cols if c not in ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏Å‡∏≥‡πÑ‡∏£‡∏™‡∏∏‡∏ó‡∏ò‡∏¥']},
                    **{c: st.column_config.NumberColumn(format="%.2f%%") for c in final_cols if '%' in c}
                },
                use_container_width=True, hide_index=True, height=600
            )

        else: st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Database")
    except Exception as e: st.error(f"Error Loading Dashboard: {e}")

# ==========================================
# TAB 3: COSTS (‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô)
# ==========================================
with tab3:
    st.subheader("üí∞ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (Master Cost)")
    try:
        res = supabase.table("product_costs").select("*").execute()
        cur_data = pd.DataFrame(res.data)
        if cur_data.empty: cur_data = pd.DataFrame(columns=['sku', 'platform', 'unit_cost'])
        
        edited = st.data_editor(
            cur_data, num_rows="dynamic", use_container_width=True, hide_index=True, key="cost_edit",
            column_config={
                "unit_cost": st.column_config.NumberColumn("‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô (‡∏ö‡∏≤‡∏ó)", format="%.2f"),
                "platform": st.column_config.SelectboxColumn("‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°", options=["TIKTOK", "SHOPEE", "LAZADA"], required=True),
                "sku": st.column_config.TextColumn("‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (SKU)", required=True),
            }
        )
        
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô"):
            if not edited.empty:
                edited['sku'] = edited['sku'].astype(str).str.strip().str.upper()
                edited['platform'] = edited['platform'].astype(str).str.strip().str.upper()
                supabase.table("product_costs").delete().neq("id", 0).execute()
                supabase.table("product_costs").insert(edited.to_dict('records')).execute()
                st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!"); st.rerun()
    except Exception as e: st.error(f"Error Cost: {e}")